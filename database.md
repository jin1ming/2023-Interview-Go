### mysql

- sql语句中group by和order by谁先执行？

​		select (all | distinct) 字段或者表达式 (from子句) (where子句) (group by子句) (having子句) (order by子句) (limit子句);

​		1、from子句:构成提供给select的数据源,所以一般后面写表名
​		2、where子句:where子句是对数据源中的数据进行过滤的条件设置
​		3、group by子句:对通过where子句过滤后的数据进行分组
​		4、having子句:对分组后的的数据进行过滤,作用和where类似
​		5、order by子句:对取得的数据结果以某个标准(字段)进行排序,默认是asc(正序)
​		6、limit子句:对取出来的数据进行数量的限制,从第几行开始取出来几行数据
​		7、all | distinct 用于设置select出来的数据是否消除重复行，默认是all既不消除所有的数据都出来；distinct表示会消除重复行

- mysql的存储引擎有哪些？都有什么区别？

​		MyISAM，InnoDB
​		区别：
​		1、MySAM不支持事务、不支持外键，而innodb支持
​		2、都是b+树作为索引结构，但是实现方式不同,innoDb是聚集索引，myisam是非聚集索引。
​		3、innoDb不保存表的具体行数，count(*)需要全表扫描，而myisam用一个变量保存了整个表的行数，速度更快。
​		4、innodb组小的锁粒度是行锁，myisam最小的锁粒度是表锁。myisam一个更新语句会锁住整张表，导致其他查询、更新都会被阻塞，因此并发当问受限。

- 为什么需要B-树/B+树？

​		因为传统的树是在内存中进行的数据搜索，而当数据量非常大时，内存不够用，大部分数据只能存放在磁盘上，只有需要的数据才加载到内存中。一般情况下内存访问的时间约为50ns,而磁盘在10ms左右，大部分时间会阻塞在磁盘IO上，因此要提高性能，得减少磁盘IO次数。

- mysql索引底层实现？

​		MyISAM引擎使用B+树作为索引结构，叶子节点的data域存放的是数据记录的地址，需要再寻址一次才能得到数据，是"非聚集索引"。

​		InnoDB引擎也使用B+树作为索引结构，区别如下：
​			1、InnoDB的叶子节点data域保存了完整的数据记录，因此主键索引很高效，是"聚集索引"。
​			2、InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询做到覆盖索引
会很高效。

​		hash索引底层的数据结构是哈希表，在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议都选择BTree索引。

- 为什么MongoDB使用B-树，而mysql使用B+树？

​		Mg是类似json格式的数据模型，对性能要求高，属于聚合型数据库，而B-树恰好key和data域聚合在一起，且最佳查询时间复杂度为O(1);

​		mysql是一种关系型数据库，B+树的特性可以增加区间访问性，而B-树并不支持；B+树的查询时间复杂度始终为O(log n)，查询效率更加稳定。

- B-树和B+树的区别？

​		1、B+树非叶子节点只存储key的副本，相当于叶子节点的索引，真实的key和data域都在叶子节点存储，查询时间复杂度固定为O(log n)，而B-树节点内部每个key都带着data域，查询时间复杂度不固定，与key在树中的位置有关，最好为O(1)。

​		2、B+树叶子节点带有顺序指针，两两相连大大增加区间访问性，利用磁盘预读提前将访问节点附近的数据读入内存，减少了磁盘IO的次数，也可使用在范围查询，而B-树每个节点key和data在一起，则无法区间查找。

​		3、磁盘是分block的，一次磁盘IO会读取若干个block，具体和操作系统有关，磁盘IO数据大小是固定的，在一次IO中，单个元素越小，量就越大。由于B+树的节点只存储key的副本，这就意味着B+树单次磁盘IO的数据大于B-树，自然磁盘IO次数也更少。

- 覆盖索引是什么？

​		从索引中就能查到记录，而不需要索引之后再回表中查记录，避免了回表的产生，减少了树的搜索次数。

​		索引设计的原则？需要注意事项？

​	    1、不要过度索引，并非索引越多也好，索引需要空间来存储，也需要定期维护，并且索引会降低写操作的性能。
​	    2、非必要情况，所有列都应该指定列为NOT NULL，使用零值作为默认值。

- 什么是数据库事务？

​		事务是一个不可分割的数据操作序列，也是数据库并发控制的基本单位，其执行结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。

- 事务的四大特性(ACID)?

​		1、原子性：事务是最小的执行单位，包含的所有数据库操作要么全部成功，要么全部失败回滚；
​		2、一致性：执行事务前后数据都必须处于一致性状态；
​		3、隔离性：一个事务未提交的业务结果是否对于其它事务可见，对应有四种事务隔离级别。
​		4、持久性：一个事务一旦被提交了，那么对数据库中数据的改变就是永久性的，即使是在数据库
​		系统遇到故障的情况下也不会丢失提交事务的操作。

- 事务隔离级别有哪些？如何解决脏读和幻读？

​		数据库定义了四种不同的事务隔离级别，由低到高依次为：
​		Read uncommitted 读取未提交-----三者均可能
​		Read committed 读取已提交------解决了脏读，可能出现不可重复读和幻读
​		Repeatable read 可重复读------可能出现幻读，解决了脏读和不可重复读
​		Serializable 可串行化（对所涉及到的表加锁，并非行级锁）

​		**脏读**:读取未提交数据(A事务读到未提交的B事务数据)
​		解决：设置事务级别为Read committed

​		**不可重复读**:前后多次读取，数据内容不一致(原因：读取了其它事务更改的数据且提交了事务，针对update操作)
​		解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，才允许其它事务操作。

​		**幻读**：前后多次读取，数据总量不一致(原因：读取了其它事务新增的数据且提交了事务，针对insert和delete操作)
​		解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，才允许其它事务操作。

​		mysql的事务隔离级别默认为Repeatable read(可重复读，可能会出现幻读)

- 乐观锁和悲观锁的实现方式？

​		乐观锁：基于数据版本号实现(基于mvcc理论)
​		悲观锁：数据库的锁机制

- innoDB存储引擎的锁的算法有那三种？

​		Record lock: 单个行记录上的锁
​		Gap lock: 间隙锁，锁定一个范围，不包括记录本身
​		Next-key lock: record+gap 锁定一个范围，包含记录本身

​		注意：(间隙：范围查询中，存在于范围内，但不存在的记录，这称为间隙)

- mysql的mvcc实现原理是什么？

​		MVCC只适用mysql事务隔离级别：Read committed 和 Repeatable Read，MVCC的版本是在事务提交之后才会产生。

​		多版本并发控制：Undo log实现MVCC，并发控制通过锁来实现。
​		简单来说就是在每一行记录的后面增加两个隐藏列，记录创建版本号和删除版本号，而每一个事务在启动的时候，都有一个唯一的递增的版本号，通过版本号来减少锁的争用。

​		1、在插入操作时，记录的创建版本号就是事务版本号；
​		2、在更新操作时，采用的是先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录；
​		3、删除操作的时候，就把事务版本号作为删除版本号；
​		4、查询时，符合删除版本号大于当前事务版本号并且创建版本号小于或者等于当前事务版本号这两个条件的记录才能被事务查询出来。

- bin log、redo log、undo log作用是什么？有什么区别？

​		bin log: 
​		记录mysql服务层产生的日志，常用来进行数据恢复、数据库复制。

​		redo log:
​		记录了数据操作在物理层面的修改。mysql中大量使用缓存，缓存存在与内存中，修改操作时会直接修改内存，而不是立刻修改磁盘，当内存和磁盘数据不一致时，称内存中的数据为脏页。

​		为了保证数据的安全性，事务进行时会不断产生redo log，在事务提交时进行一次flush操作，保存到磁盘中，redo log是按照顺序写入的，磁盘的顺序读写的速度远大于随机读写。当数据库或主机失效重启时，会根据redo log进行数据的恢复，如果redo log中有事务提交，则进行事务提交修改数据。这样实现了事务的原子性、一致性、持久性。

​		undo log:
​		当进行数据修改时除了记录redo log，还会记录undo log，它记录了修改的反向操作，用于数据的撤回操作，可以实现事务回滚，mvcc就是根据undo log实现回溯到某个特定的版本的数据的。

- 大表数据查询，如何优化？

​		1、优化sql语句+索引
​		2、增加缓存，memcached、redis
​		3、做主从复制，读写分离
​		4、拆表---垂直拆分、水平拆分

- Mysql数据库cpu飙升如何排查？

​		1、首先top查看是否真是由于mysqld占用导致的。
​		2、show processlist，分析session情况，有没有激增，是不是有消耗资源的sql在运行。
​		3、找出消耗高的sql，explain查看执行计划。

- 主从复制的实现步骤？

​		1、主库db的操作事件被写入到 binlog
​		2、从库发起连接，连接到主库
​		3、此时主库创建一个 binlog dump thread 线程，把binlog的内容发送到从库
​		4、从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log
​		5、还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置
​		开始执行读取到的操作事件，将内容写入到slave的db

### kafka

- kafka为什么性能高？

​		1、kafka本身是分布式集群，同时采用了分区技术，具有较高的并发度；
​		2、顺序写入磁盘，Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。
​		3、零拷贝技术

- kafka重复消费可能的原因以及处理方式？

​		原因1：消费者宕机、重启等，导致消息已经消费但是没有提交offset；
​		原因2：消费者使用自动提交offset，但当还没有提交的时候，有新的消费者加入或者移除，发生了rebalance。再次消费的时候，消费者会根据提交的偏移量来，于是重复消费了数据。
​		原因3：消息处理耗时，或者消费者拉取的消息量太多，处理耗时，超过了max.poll.interval.ms的配置时间，导致认为当前消费者已经死掉，触发再均衡。

​		解决方案：消费者实现消费幂
​		1、消费表
​		2、数据库唯一索引
​		3、缓存消费过的消息ID

- 触发重平衡(rebalanced)的情况？

​		1、有新的消费者加入消费组、或已有消费者主动离开组
​		2、消费者超过session时间未发送心跳（已有 consumer 崩溃了）
​		3、一次poll()之后的消息处理时间超过了max.poll.interval.ms的配置时间，因为一次poll()处理完才会触发下次poll()（已有 consumer 崩溃了）
​		4、订阅主题数发生变更
​		5、订阅主题的分区数发生变更

- kafka消息丢失的原因以及解决方式？

​		生产者丢失消息情况：可能因为网络问题并没有发送出去。
​		解决：可以给send方法添加回调函数,按一定次数、间隔重试。

​		消费者丢失消息情况：消费者自动提交offset，拿到消息还未真正消费，就挂掉了，但是offset却被自动提交了。
​		解决：关闭自动提交offset，每次在真正消费完消息之后之后再自己手动提交offset，这样解决了消息丢失，但会带来重复消费问题。

- kafka丢失消息情况：
  leader副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些
  没有被 follower 副本的同步的话，就会造成消息丢失。

​		解决：设置 ack = all。ack是Kafka生产者很重要的一个参数。代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。

- Kafka中的消息有序吗？

​		kafka无法保证整个topic多个分区有序，但是由于每个分区（partition）内，每条消息都有一个offset，故可以保证分区内有序

- topic的分区数可以增加或减少吗？为什么？

​		topic的分区数只能增加不能减少，因为减少掉的分区也就是被删除的分区的数据难以处理.

​		注意：消费者组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据.

- kafka是怎么维护offset的？

​		维护offset的原因：
​		由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。

​		维护offset的方式：
​		Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为**__consumer_offsets**。

​		关于offset的常识：
​		消费者提交消费位移时提交的是当前消费到的最新消息的offset+1而不是offset。

- kafka集群消息积压问题如何处理？

​		从两个角度去分析：
​		1、如果是 Kafka 消费能力不足，则可以考虑增加 Topic 的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）
​		2、如果是下游的数据处理不及时，提高每批次拉取的数量。如果是因为批次拉取数据过少（拉取 数据/处理时间<生产速度），也会使处理的数据小于生产的数据，造成数据积压。

### redis

- redis单线程为什么效率也这么高？

  1.redis是基于内存的，内存的读写速度非常快.

  2.redis是单线程的，省去了很多上下文切换线程的时间.

  3.IO多路复用

- redis有那五种常用的数据结构？应用场景以及实现原理是什么？

​	ziplist: 压缩列表，此数据结构是为了节约内存而开发
​	intset: 整数集合，是集合键的底层实现方式之一
​	quicklist：ziplist的一个双向链表
​	skiplist：跳表
```
1. string              计数             sds(raw，embstr，int)
2. hash                缓存结构数据       quicklist(hashtable，ziplist)
3. list                异步消息队列       (ziplist，linkedlist)
4. set(无序、成员唯一)   计算共同喜好(交集)、统计访问ip     (intset，hashtable)
5. zset(有序、成员唯一)  排行榜、延迟队列        (ziplist，skiplist)
```

- redis的过期策略？

​		定期删除+惰性删除策略

​		定期删除策略：Redis 启用一个定时器定时监视所有的 key，判断key是否过期，过期的话就删除。 这种策略可以保证过期的 key 最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗 CPU 资源，并且当 key 已过期，但是定时器还处于未唤起状态，这段时间内 key 仍然可以用。

​		惰性删除策略：在获取 key 时，先判断 key 是否过期，如果过期则删除。这种方式存在一个缺点：如果这个 key 一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。

​		这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不在是每次扫描全部的 key 了，而是随机抽取一部分 key 进行检查，这样就降低了对 CPU 资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求。但是有时候就是那么的巧，既没有被定时器抽取到，又没有被使用，这些数据又如何从内存中消失？没关系，还有内存淘汰机制，当内存不够用时，内存淘汰机制就会上场。

- Redis中的批量操作Pipeline？

​		非pipeline：client一个请求，redis server一个响应，期间client阻塞。
​		Pipeline：redis的管道命令，允许client将多个请求依次发给服务器，过程中不需要等待请求的回复，而是在最后读取所有结果。

- redis与mysql数据一致性解决方案？

​		延迟双删策略：
​		1、先删除缓存，然后更新数据库，但可能在更新未完成之前，有请求穿透到db取了旧数据并写入了缓存，因此需要更新完数据库之后，延迟几十毫秒，再删一次缓存。
​		2、先更新数据库，再删除缓存，再延迟删一次。如果删除失败则重试，比如放入队列循环删除。

- 发生缓存穿透、击穿、雪崩的原因以及解决方案？

​		缓存穿透
​		是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。(简单来说就是缓存和数据库 都不存在这个数据，这种情况称为穿透)

​		解决方案：
​		1、接口层增加校验，比如id<=0这种一定不存在的情况直接拦截掉。
​		2、如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
​		3、采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

​		缓存雪崩
​		缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。重启导致缓存失效，也可能出现并发到DB。
​		解决方案：
​		1、考虑用加锁(互斥锁)，锁定key之后完成db的查询以及缓存的更新之后再释放锁定key，从而避免失效时大量的并发请求落到底层存储系统上。
​		2、缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
​		3、重启导致缓存失效，我们可以采用缓存预热，提前使用一个接口更新好缓存，再启动服务。

​		缓存击穿(场景：热点数据)
​		缓存中不存在，但数据库中有的数据(一般是缓存时间到期)。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。与雪崩区别是击穿指并发查同一条数据。
​		解决方案：
​		1、使用互斥锁(SETNX)
​		2、设置热点数据永远不过期，数据是需要维护的。

- redis的持久化方案RDB和AOF详解？

​		RDB:在指定的时间间隔内将内存中的数据集快照写入磁盘，它恢复时就是将快照文件直接读到内存里。
​		AOF:持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾,Redis 还可以在后台对 AOF 文件进行重写(rewrite)，使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小
