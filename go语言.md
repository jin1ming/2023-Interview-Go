# golang

目录：

[TOC]

---

## 基础

### go语言有什么优点和缺点

优势：容易学习，生产力，并发，动态语法。劣势：包管理，错误处理，缺乏框架，cgo繁琐。

### 数组和切片有什么区别？

- go语言中数组是一种值类型，[2]int和[3]int是两种不同的类型；切片类型只和它的基础数据类型有关，如[]int和[]string.

- 数组本身的赋值和传参都是以整体复制进行处理的；而切片复制的只有切片头部分信息，因为包含底层数据指针。

- 切片可以扩容

- 切片基于数组：

  ```
  type SliceHeader struct {
    Data uintptr
    len int
    Cap int
   }
  ```

### 字符串和数组有什么区别？

  - 字符串底层数据是对应的字节数组，但字符串的只读属性禁止了在程序中对字节数组的元素进行修改。
  - 字符串赋值只复制了数据地址和对应的长度，不会复制底层数据。（使用不当会造成内存泄漏）

### new和make区别

- make 只能用来分配及初始化类型为 slice、map、chan 的数据。new 可以分配任意类型的数据；
- new 分配返回的是指针，即类型 *Type。make 返回引用，即 Type；
- new 分配的空间被清零。make 分配空间后，会进行初始化；

### 进程、线程、协程区别

- 进程是应用程序的实体，分配操作系统资源的最小单位，拥有自己的内存空间以及堆栈。

- 线程是内核操作系统调度CPU的基本单位，在进程的内存空间及堆栈上进行执行运行。

- 协程指的是用户态线程，由用户的应用程序进行调度 

  一般协程利用多核优势采用进程+协程，go协程采用内核线程+协程实现

### 协程的好处

a. 切换上下文代价小，协程切换时不用进行系统调用，走内核态的指令。

b. 创建和销毁的代价小，线程需要和操作系统打交道，是内核级。

c.内存占用小，只占用 2K，线程占用 2M

### CSP并发模型(通信顺序进程)

不要通过共享内存来通信，而要通过通信来实现内存共享。

​	CSP并发模型它并不关注发送消息的实体，而关注的是发送消息时使用的channel，go语言借用了process和channel这两个概念，process表现为go里面的goroutine，是实际并发执行的实体，每个实体之间是通过channel来进行匿名传递消息使之解藕，从而达到通讯来实现数据共享。

​	同时，借助Go语言调度器的设计，可以高效实现通道的堵塞/唤醒，进一步实现通道多路复用的机制。

​	另外与select结合，可以避免由于一个通道的读写陷入阻塞。

## 锁

### golang有哪些锁？

原子锁、互斥锁、读写锁

### 原子锁/自旋锁:

- `atomic.CompareAndSwapInt64(&flag), 0, 0)`
- 缺点：1.CPU开销大；2.不能保证代码的原子性；3.ABA问题（版本号+时间戳解决）

### 互斥锁：

混合公平锁，结合了原子操作、自旋、信号量、全局哈希表、等待队列、操作系统级别锁。

ps: 公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。

- 包含了Lock和TryLock两种调用

- 另种模式：正常模式、饥饿模式（1ms没获取到锁）

- sync.Mutex 更轻量级的锁，解决原子锁CPU开销大的问题。

- 实现：
  ```go
  type Mutex struct {
     state int32 // 锁状态
     sema uint32 // 信号量
  }
  ```
  state锁状态为互斥锁位图（默认都为0），包含：
  - 1.waiterCount:正在等待被唤醒的协成数量；2.starving:当前进入饥饿状态；3.woken:协程准备从正常状态下被唤醒；4.locked:锁定状态
  
  上锁阶段：
  1. CAS快速抢占锁。成功就返回，失败调用lockSow。
  
  2. 信号量同步。加锁信号量-1，解锁信号量+1
  
  3. 所有锁存储在全局semtable哈希表。
  
  释放阶段：
  
  1. 普通状态（非饥饿和唤醒）：Unlock()使用atomic.Addint32修改状态。否则，调用unlockSlow()。2. 判断是否重复释放。3. 饥饿状态：进入信号量同步阶段，全局哈希表寻找锁等待队列，先入先出顺序唤醒指定协程。
  
  4. 非饥饿状态：如果互斥锁不存在等待者或者互斥锁的 `mutexLocked`、`mutexStarving`、`mutexWoken` 状态不都为 0，那么当前方法可以直接返回，不需要唤醒其他等待者；如果互斥锁存在等待者，会通过`runtime_Semrelease`唤醒等待者并移交锁的所有权。
  

## Channel

### channel底层的数据结构是什么？发送和接收元素的本质是什么？

```go
type hchan struct {
    qcount   uint           // *chan里元素数量
    dataqsiz uint           // *底层循环数组的长度，就是chan的容量
    buf      unsafe.Pointer // *指向大小为dataqsiz的数组，有缓冲的channel
    elemsize uint16         // chan中的元素大小
    closed   uint32         // chan是否被关闭的标志
    elemtype *_type         // chan中元素类型
    recvx    uint           // *当前可以接收的元素在底层数组索引(<-chan)
    sendx    uint           // *当前可以发送的元素在底层数组索引(chan<-)
    recvq    waitq          // 等待接收的协程队列(<-chan)
    sendq    waitq          // 等待发送的协程队列(chan<-)
    lock     mutex          // 互斥锁,保证每个读chan或者写chan的操作都是原子的
}

// waitq是sudog的一个双向链表，sudog实际上是对goroutine的一个封装。
type waitq struct {
	first *sudog
	last  *sudog
}

// channel的发送和接收操作本质上都是"值的拷贝"(只是拷贝它的值而已)，
```

### channel使用应该注意哪些情况，在哪些情况下会死锁/阻塞？
​	1、一个无缓冲channel在一个主go程里同时进行读和写；
​	2、无缓冲channel在go程开启之前使用通道；
​	3、通道1中调用了通道2，通道2中调用了通道1；
​	4、读取空的channel；
​	5、超过channel缓存继续写入数据；
​	6、向已经关闭的channel中写入数据不会导致死锁，但会Panic异常。
​	7、close一个已经关闭的channel会Panic异常。

## Map

### map的底层实现原理是什么？

在go中map是数组存储的，采用的是哈希查找表，通过哈希函数将key分配到不同的bucket。

每个bucket中可以存储8个kv键值对，当每个bucket存储的kv对到达8个之后，会通过overflow指针指向一个新的bucket，从而形成一个链表。

### map的存储是有序的吗

存储结构上由于在扩容的时候会将 key 随机分流到另外两个桶，这导致了 key  的相对位置会发生改变，所以 key 是无序的。

遍历上来说，每次遍历是取一个随机数，随机从一个桶开始遍历。所以每次遍历出来的结果都是不一样的。

额外一点是，当未发生扩容前，key 的相对位置是确定的。

### map的key的定位过程是怎样的？
​	对key计算hash值，计算它落到那个桶时，只会用到最后B个bit位，再用哈希值的高8位找到key在bucket中的位置。桶内没有key会找第一个空位放入，冲突则从前往后找到第一个空位。

### map的扩容和缩容

**扩容**分为了翻倍扩容、等量扩容。还有确定了要扩容后，使用的是渐进式扩容去避免性能抖动。

扩容的触发条件有两个，**状态装载因子超过 6.5**（现在的桶装在的元素超过 80 %），也就是元素太多了，或者**溢出桶太多**，也就是太多元素被删除，元素非常稀疏。 前者会使用翻倍扩容，会申请现有翻倍的空间。当有读操作时仍会访问旧桶，当有插入或者删除操作的时候会将旧桶分流到两个新桶。后者会使用等倍扩容，重新申请一块和现有大小相同的新桶，也是使用渐进式扩容在插入或者删除操作中进行。

go 的 map 没有缩容的机制。map 内部的存储结构是基于拉链法的，里面的元素如果被大批量的删除后，会触发等量扩容。等量扩容时会申请原有大小一样的内存块，渐进式的扩容过去，让原有的 map 中因为很多元素被删除后导致元素排序稀疏的情况经过 rehash 后会排序会变得紧密，减少溢出桶的使用

## sync.Map

1. 通过 read 和 dirty 两个字段将**读写分离**，读的数据存在只读字段 read 上，将最新写入的数据则存在 dirty 字段上
2. 读取时会先查询 read，不存在再查询 dirty，写入时则只写入 dirty
3. 读取 read 并不需要加锁，而读或写 dirty 都需要加锁
4. 另外有 misses 字段来统计 read 被穿透的次数（被穿透指需要读 dirty 的情况），超过一定次数则将 dirty 数据同步到 read 上
5. 对于删除数据则直接通过标记来延迟删除

## 其他

### 内存泄漏场景，及如何解决？

  - 切片/字符串引用不当：先对需要引用的进行拷贝，再引用
  - ~~频繁的系统调用~~
  - for循环中使用defer：在for中构建一个局部函数，在函数内部执行defer
  - goroutine泄露
    如：Ticker使用忘记Stop，通常使用context来避免。

解决：

​	1、通过pprof工具获取内存相差较大的两个时间点heap数据。htop可以查看内存增长情况。
​	2、通过go tool pprof比较内存情况，分析多出来的内存。
​	3、分析代码、修复代码。

### Gin的启动过程

项目的main函数

主函数位于项目根目录下的main.go中，代码如下：

```
package main

import (
	"github.com/LearnGin/handler"
	"github.com/LearnGin/middleware"
	"github.com/gin-gonic/gin"
)

func main() {
	// init gin with default configs
	r := gin.Default()

	// append custom middle-wares
	middleware.RegisterMiddleware(r)
	// register custom routers
	handler.RegisterHandler(r)

	// run the engine
	r.Run()
}
```

主要步骤：

1. 初始化Gin

   ```
   gin.Default()
   ```

   执行Gin的初始化过程，默认的初始化包含两个中间件，

   1. **Logger**：日志中间件，将Gin的启动与响应日志输出到控制台；
   2. **Recovery**：恢复中间件，将Gin遇到的无法处理的请求按HTTP 500状态码返回。

2. **注册中间件**：本例的`middleware.RegisterMiddleware(r)`用于将项目中开发的中间件注册到Gin Engine上；

3. **注册事件处理**：本例的`handler.RegisterHandler(r)`用于将项目中开发的对应于指定URL的事件处理函数注册到Gin Engine上；

4. **启动Gin**：`r.Run()`负责启动Gin Engine，开始监听请求并提供HTTP服务。

### iface和eface的区别是什么？值接收者和指针接收者的区别？
​	iface和eface都是Go中描述接口的底层结构体，区别在于iface包含方法。而eface则是不包含任何方法的空接口：interface{}

​	注意：编译器会为所有接收者为T的方法生成接收者为*T的包装方法，但是链接器会把程序中确定不会用到的方法都裁剪掉。因此*T和T不能定义同名方法。
​	生成包装方法是为了接口，因为接口不能直接使用接收者为值类型的方法。
​	如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；如果方法的接收者是指针类型，则调用者修改的是指针指向的对象本身。
​	如果类型具备"原始的本质"，如go中内置的原始类型，就定义值接收者就好。
​	如果类型具备"非原始的本质"，不能被安全的复制，这种类型总是应该被共享，则可定义为指针接收者。

## 内存逃逸分析

编译阶段确定分配在堆还是栈

指针必然发生逃逸的三种情况（go version go1.13.4 darwin/amd64)：

> 1. 在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）；
> 2. 被已经逃逸的变量引用的指针，一定发生逃逸；
> 3. 被指针类型的slice、map和chan引用的指针，一定发生逃逸；

引用内存逃逸的典型情况：

1. **在函数内部返回把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此生命周期大于栈，则溢出
2. **发送指针或带有指针的值到channel中** 在编译时，是没办法知道哪个 goroutine 会在 channel上接受数据，所以编译器没办法知道变量什么时候释放。
3. **在一个切片上存储指针或带指针的值** 一个典型的例子就是 []*string，这会导致切片的内容逃逸，尽管其后面的数组在栈上分配，但其引用值一定是在堆上
4. **slice 的背后数组被重新分配了** 因为 append 时可能会超出其容量( cap )。 slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
5. **在 interface 类型上调用方法** 如fmt包 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。

## 内存分配

Go的内存分配模仿了 TCMalloc (Thread-Caching Malloc) 的设计，核心思想是**多级缓存**和**按照大小分类**，目的是减少锁竞争和内存碎片。

### 核心组件

1.  **mspan (内存块)**
    - 内存管理的基本单位。
    - 由一组连续的页（Page，通常8KB）组成。
    - 划分为特定大小的 slot（槽），用于存放对象。

2.  **mcache (线程缓存)**
    - **绑定到 P (Processor)**，即每个 P 都有自己的 mcache。
    - **无锁访问**：因为 P 同一时间只能运行一个 G，所以不需要锁，速度极快。
    - 包含所有规格（class）的 mspan（tiny, small 等）。

3.  **mcentral (中心缓存)**
    - 所有 P 共享。
    - **需要加锁**。
    - 当 mcache 中的 mspan 用完时，从 mcentral 申请新的 mspan。
    - 包含两个链表：`nonempty`（有空闲 slot）和 `empty`（无空闲 slot，已被 mcache 取走或已满）。

4.  **mheap (堆)**
    - 全局唯一的堆内存。
    - **需要加锁**。
    - 当 mcentral 没有空闲 mspan 时，从 mheap 申请。
    - 如果 mheap 不够，向操作系统申请（`mmap`）。
    - 包含 `treap` 或 `radix tree` 管理未使用的 span。

### 分配流程

根据对象大小，分配策略不同：

1.  **微对象 (Tiny) < 16B**
    - 使用 mcache 的微型分配器，将多个微对象合并到一个 16B 的块中，减少浪费。

2.  **小对象 (Small) 16B ~ 32KB**
    - **mcache**: 计算大小规格 (Size Class)，在 mcache 对应的 mspan 查找空闲 slot。
    - **mcentral**: 如果 mcache 满了，向 mcentral 申请带有空闲 slot 的 mspan。
    - **mheap**: 如果 mcentral 也没了，向 mheap 申请一组页，生成新的 mspan。

3.  **大对象 (Large) > 32KB**
    - 直接跳过 mcache 和 mcentral，从 **mheap** 申请分配，直接分配一组连续的页（span）。

---

## 垃圾回收 (GC)

Go 使用的是 **无分代 (Non-Generational)**、**并发 (Concurrent)**、**三色标记清除 (Tri-color Mark and Sweep)** 算法。

### 三色标记法原理

对象被分为三种颜色：

-   **白色 (White)**: 潜在的垃圾。GC 开始时所有对象都是白色。GC 结束时仍为白色的对象将被清除。
-   **灰色 (Grey)**: 活跃对象，但其引用的子对象还没有被扫描完。
-   **黑色 (Black)**: 活跃对象，且其引用的所有子对象都已扫描完。

**过程：**
1.  所有对象初始为白色。
2.  **根节点** (栈上的变量、全局变量) 被标记为灰色。
3.  从灰色集合取出一个对象，标记为黑色，并将其引用的白色子对象标记为灰色。
4.  重复步骤3，直到灰色集合为空。
5.  剩余的白色对象即为垃圾，进行回收。

### 写屏障 (Write Barrier)

由于 GC 和用户代码 (Mutator) 是并发运行的，用户代码可能会在标记过程中修改引用关系，导致**对象丢失**（例如黑色对象引用了白色对象，而该白色对象被漏标）。

Go 1.8 引入了 **混合写屏障 (Hybrid Write Barrier)**，结合了 插入写屏障 和 删除写屏障 的优点：

-   **核心规则**：
    1.  GC 开始将栈上所有对象扫描并标记为黑色（无需 STW 重新扫描栈）。
    2.  GC 期间，任何在栈上创建的新对象均为黑色。
    3.  被删除的引用对象标记为灰色。
    4.  被添加的引用对象标记为灰色。

-   **目的**：极大减少了 STW (Stop The World) 的时间，不再需要在重新扫描阶段对栈进行 STW。

### GC 触发时机

1.  **主动触发**: 调用 `runtime.GC()`。
2.  **被动触发**:
    -   **GOGC**: 默认 100%。当堆内存增长到上次 GC 后存活堆内存的 2 倍时触发。
    -   **定时触发**: 默认 2 分钟没有 GC，强制触发 (`sysmon` 检测)。

### GC 阶段

1.  **Mark Setup (STW)**: 开启写屏障。
2.  **Marking (Concurrent)**: 并发标记，占用 25% CPU。
3.  **Mark Termination (STW)**: 关闭写屏障，计算清理任务。
4.  **Sweep (Concurrent)**: 并发清理，在分配内存时懒惰触发或后台触发。