# golang

目录：

[TOC]

---

## 基础

### go语言有什么优点和缺点

优势：容易学习，生产力，并发，动态语法。劣势：包管理，错误处理，缺乏框架，cgo繁琐。

### 数组和切片有什么区别？

- go语言中数组是一种值类型，[2]int和[3]int是两种不同的类型；切片类型只和它的基础数据类型有关，如[]int和[]string.

- 数组本身的赋值和传参都是以整体复制进行处理的；而切片复制的只有切片头部分信息，因为包含底层数据指针。

- 切片可以扩容

- 切片基于数组：

  ```
  type SliceHeader struct {
    Data uintptr
    len int
    Cap int
   }
  ```

### 字符串和数组有什么区别？

  - 字符串底层数据是对应的字节数组，但字符串的只读属性禁止了在程序中对字节数组的元素进行修改。
  - 字符串赋值只复制了数据地址和对应的长度，不会复制底层数据。（使用不当会造成内存泄漏）

### new和make区别

- make 只能用来分配及初始化类型为 slice、map、chan 的数据。new 可以分配任意类型的数据；
- new 分配返回的是指针，即类型 *Type。make 返回引用，即 Type；
- new 分配的空间被清零。make 分配空间后，会进行初始化；

### 进程、线程、协程区别

- 进程是应用程序的实体，分配操作系统资源的最小单位，拥有自己的内存空间以及堆栈。

- 线程是内核操作系统调度CPU的基本单位，在进程的内存空间及堆栈上进行执行运行。

- 协程指的是用户态线程，由用户的应用程序进行调度 

  一般协程利用多核优势采用进程+协程，go协程采用内核线程+协程实现

### 协程的好处

a. 切换上下文代价小，协程切换时不用进行系统调用，走内核态的指令。

b. 创建和销毁的代价小，线程需要和操作系统打交道，是内核级。

c.内存占用小，只占用 2K，线程占用 2M

### CSP并发模型(通信顺序进程)

不要通过共享内存来通信，而要通过通信来实现内存共享。

​	CSP并发模型它并不关注发送消息的实体，而关注的是发送消息时使用的channel，go语言借用了process和channel这两个概念，process表现为go里面的goroutine，是实际并发执行的实体，每个实体之间是通过channel来进行匿名传递消息使之解藕，从而达到通讯来实现数据共享。

​	同时，借助Go语言调度器的设计，可以高效实现通道的堵塞/唤醒，进一步实现通道多路复用的机制。

​	另外与select结合，可以避免由于一个通道的读写陷入阻塞。

## 锁

### golang有哪些锁？

原子锁、互斥锁、读写锁

### 原子锁/自旋锁:

- `atomic.CompareAndSwapInt64(&flag), 0, 0)`
- 缺点：1.CPU开销大；2.不能保证代码的原子性；3.ABA问题（版本号+时间戳解决）

### 互斥锁：

混合公平锁，结合了原子操作、自旋、信号量、全局哈希表、等待队列、操作系统级别锁。

ps: 公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。

- 包含了Lock和TryLock两种调用

- 另种模式：正常模式、饥饿模式（1ms没获取到锁）

- sync.Mutex 更轻量级的锁，解决原子锁CPU开销大的问题。

- 实现：
  ```go
  type Mutex struct {
     state int32 // 锁状态
     sema uint32 // 信号量
  }
  ```
  state锁状态为互斥锁位图（默认都为0），包含：
  - 1.waiterCount:正在等待被唤醒的协成数量；2.starving:当前进入饥饿状态；3.woken:协程准备从正常状态下被唤醒；4.locked:锁定状态
  
  上锁阶段：
  1. CAS快速抢占锁。成功就返回，失败调用lockSow。
  
  2. 信号量同步。加锁信号量-1，解锁信号量+1
  
  3. 所有锁存储在全局semtable哈希表。
  
  释放阶段：
  
  1. 普通状态（非饥饿和唤醒）：Unlock()使用atomic.Addint32修改状态。否则，调用unlockSlow()。2. 判断是否重复释放。3. 饥饿状态：进入信号量同步阶段，全局哈希表寻找锁等待队列，先入先出顺序唤醒指定协程。
  
  4. 非饥饿状态：如果互斥锁不存在等待者或者互斥锁的 `mutexLocked`、`mutexStarving`、`mutexWoken` 状态不都为 0，那么当前方法可以直接返回，不需要唤醒其他等待者；如果互斥锁存在等待者，会通过`runtime_Semrelease`唤醒等待者并移交锁的所有权。
  

## Channel

### channel底层的数据结构是什么？发送和接收元素的本质是什么？

```go
type hchan struct {
    qcount   uint           // *chan里元素数量
    dataqsiz uint           // *底层循环数组的长度，就是chan的容量
    buf      unsafe.Pointer // *指向大小为dataqsiz的数组，有缓冲的channel
    elemsize uint16         // chan中的元素大小
    closed   uint32         // chan是否被关闭的标志
    elemtype *_type         // chan中元素类型
    recvx    uint           // *当前可以接收的元素在底层数组索引(<-chan)
    sendx    uint           // *当前可以发送的元素在底层数组索引(chan<-)
    recvq    waitq          // 等待接收的协程队列(<-chan)
    sendq    waitq          // 等待发送的协程队列(chan<-)
    lock     mutex          // 互斥锁,保证每个读chan或者写chan的操作都是原子的
}

// waitq是sudog的一个双向链表，sudog实际上是对goroutine的一个封装。
type waitq struct {
	first *sudog
	last  *sudog
}

// channel的发送和接收操作本质上都是"值的拷贝"(只是拷贝它的值而已)，
```

### channel使用应该注意哪些情况，在哪些情况下会死锁/阻塞？
​	1、一个无缓冲channel在一个主go程里同时进行读和写；
​	2、无缓冲channel在go程开启之前使用通道；
​	3、通道1中调用了通道2，通道2中调用了通道1；
​	4、读取空的channel；
​	5、超过channel缓存继续写入数据；
​	6、向已经关闭的channel中写入数据不会导致死锁，但会Panic异常。
​	7、close一个已经关闭的channel会Panic异常。

## Map

### map的底层实现原理是什么？

在go中map是数组存储的，采用的是哈希查找表，通过哈希函数将key分配到不同的bucket。

每个bucket中可以存储8个kv键值对，当每个bucket存储的kv对到达8个之后，会通过overflow指针指向一个新的bucket，从而形成一个链表。

### map的存储是有序的吗

存储结构上由于在扩容的时候会将 key 随机分流到另外两个桶，这导致了 key  的相对位置会发生改变，所以 key 是无序的。

遍历上来说，每次遍历是取一个随机数，随机从一个桶开始遍历。所以每次遍历出来的结果都是不一样的。

额外一点是，当未发生扩容前，key 的相对位置是确定的。

### map的key的定位过程是怎样的？
​	对key计算hash值，计算它落到那个桶时，只会用到最后B个bit位，再用哈希值的高8位找到key在bucket中的位置。桶内没有key会找第一个空位放入，冲突则从前往后找到第一个空位。

### map的扩容和缩容

**扩容**分为了翻倍扩容、等量扩容。还有确定了要扩容后，使用的是渐进式扩容去避免性能抖动。

扩容的触发条件有两个，**状态装载因子超过 6.5**（现在的桶装在的元素超过 80 %），也就是元素太多了，或者**溢出桶太多**，也就是太多元素被删除，元素非常稀疏。 前者会使用翻倍扩容，会申请现有翻倍的空间。当有读操作时仍会访问旧桶，当有插入或者删除操作的时候会将旧桶分流到两个新桶。后者会使用等倍扩容，重新申请一块和现有大小相同的新桶，也是使用渐进式扩容在插入或者删除操作中进行。

go 的 map 没有缩容的机制。map 内部的存储结构是基于拉链法的，里面的元素如果被大批量的删除后，会触发等量扩容。等量扩容时会申请原有大小一样的内存块，渐进式的扩容过去，让原有的 map 中因为很多元素被删除后导致元素排序稀疏的情况经过 rehash 后会排序会变得紧密，减少溢出桶的使用

## sync.Map

1. 通过 read 和 dirty 两个字段将**读写分离**，读的数据存在只读字段 read 上，将最新写入的数据则存在 dirty 字段上
2. 读取时会先查询 read，不存在再查询 dirty，写入时则只写入 dirty
3. 读取 read 并不需要加锁，而读或写 dirty 都需要加锁
4. 另外有 misses 字段来统计 read 被穿透的次数（被穿透指需要读 dirty 的情况），超过一定次数则将 dirty 数据同步到 read 上
5. 对于删除数据则直接通过标记来延迟删除

## 其他

### 内存泄漏场景，及如何解决？

  - 切片/字符串引用不当：先对需要引用的进行拷贝，再引用
  - ~~频繁的系统调用~~
  - for循环中使用defer：在for中构建一个局部函数，在函数内部执行defer
  - goroutine泄露
    如：Ticker使用忘记Stop，通常使用context来避免。

解决：

​	1、通过pprof工具获取内存相差较大的两个时间点heap数据。htop可以查看内存增长情况。
​	2、通过go tool pprof比较内存情况，分析多出来的内存。
​	3、分析代码、修复代码。

### Gin的启动过程

项目的main函数

主函数位于项目根目录下的main.go中，代码如下：

```
package main

import (
	"github.com/LearnGin/handler"
	"github.com/LearnGin/middleware"
	"github.com/gin-gonic/gin"
)

func main() {
	// init gin with default configs
	r := gin.Default()

	// append custom middle-wares
	middleware.RegisterMiddleware(r)
	// register custom routers
	handler.RegisterHandler(r)

	// run the engine
	r.Run()
}
```

主要步骤：

1. 初始化Gin

   ```
   gin.Default()
   ```

   执行Gin的初始化过程，默认的初始化包含两个中间件，

   1. **Logger**：日志中间件，将Gin的启动与响应日志输出到控制台；
   2. **Recovery**：恢复中间件，将Gin遇到的无法处理的请求按HTTP 500状态码返回。

2. **注册中间件**：本例的`middleware.RegisterMiddleware(r)`用于将项目中开发的中间件注册到Gin Engine上；

3. **注册事件处理**：本例的`handler.RegisterHandler(r)`用于将项目中开发的对应于指定URL的事件处理函数注册到Gin Engine上；

4. **启动Gin**：`r.Run()`负责启动Gin Engine，开始监听请求并提供HTTP服务。

### iface和eface的区别是什么？值接收者和指针接收者的区别？
​	iface和eface都是Go中描述接口的底层结构体，区别在于iface包含方法。而eface则是不包含任何方法的空接口：interface{}

​	注意：编译器会为所有接收者为T的方法生成接收者为*T的包装方法，但是链接器会把程序中确定不会用到的方法都裁剪掉。因此*T和T不能定义同名方法。
​	生成包装方法是为了接口，因为接口不能直接使用接收者为值类型的方法。
​	如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；如果方法的接收者是指针类型，则调用者修改的是指针指向的对象本身。
​	如果类型具备"原始的本质"，如go中内置的原始类型，就定义值接收者就好。
​	如果类型具备"非原始的本质"，不能被安全的复制，这种类型总是应该被共享，则可定义为指针接收者。

## 内存逃逸分析

编译阶段确定分配在堆还是栈

指针必然发生逃逸的三种情况（go version go1.13.4 darwin/amd64)：

> 1. 在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）；
> 2. 被已经逃逸的变量引用的指针，一定发生逃逸；
> 3. 被指针类型的slice、map和chan引用的指针，一定发生逃逸；

引用内存逃逸的典型情况：

1. **在函数内部返回把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此生命周期大于栈，则溢出
2. **发送指针或带有指针的值到channel中** 在编译时，是没办法知道哪个 goroutine 会在 channel上接受数据，所以编译器没办法知道变量什么时候释放。
3. **在一个切片上存储指针或带指针的值** 一个典型的例子就是 []*string，这会导致切片的内容逃逸，尽管其后面的数组在栈上分配，但其引用值一定是在堆上
4. **slice 的背后数组被重新分配了** 因为 append 时可能会超出其容量( cap )。 slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
5. **在 interface 类型上调用方法** 如fmt包 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。