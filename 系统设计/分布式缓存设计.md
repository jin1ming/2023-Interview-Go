# 分布式缓存设计

## 一、核心问题

| 问题 | 说明 |
|------|------|
| 缓存穿透 | 查询不存在的数据，请求打到DB |
| 缓存击穿 | 热点key过期，大量请求打到DB |
| 缓存雪崩 | 大量key同时过期，DB被打垮 |
| 数据一致性 | 缓存与DB数据不一致 |

---

## 二、一致性哈希

### 普通哈希的问题

- **算法**：`Hash(key) % N` (N = 机器数量)
- **致命缺陷**：**抗伸缩性差**
    - 当 N 发生变化（扩容或宕机）时，公式中的除数变了，导致几乎所有 Key 的计算结果都会改变。
    - **后果**：缓存全量失效（Cache Stampede），海量请求瞬间打崩数据库（雪崩）。

### 一致性哈希原理

- **核心思想**：将数据和节点都映射到一个首尾相连的哈希环上（0 ~ 2^32-1）。
- **查找规则**：
    1. 计算 Key 的哈希值，确定在环上的位置。
    2. **顺时针**查找遇到的第一个节点，即为数据归属节点。
- **优势**：
    - **平滑扩容**：增加节点 D，只会分担其逆时针方向相邻节点的一部分数据，其他节点不受影响。
    - **容灾**：节点宕机，其流量只会顺延给顺时针方向的下一个节点。

### 虚拟节点 (Virtual Nodes)

- **解决问题**：**数据倾斜**（Data Skew）。当物理节点少时，可能在环上分布不均，导致某台机器负载过高。
- **方案**：为每个物理节点创建多个虚拟副本（如 Node A#1, Node A#2...）。
- **效果**：虚拟节点随机散落在环上，使数据更均匀地分布到物理机器中。

```go
type ConsistentHash struct {
    ring       map[uint32]string  // 哈希值 → 节点
    sortedKeys []uint32           // 排序的哈希值
    replicas   int                // 虚拟节点数
}

func (c *ConsistentHash) Add(node string) {
    for i := 0; i < c.replicas; i++ {
        hash := c.hash(fmt.Sprintf("%s#%d", node, i))
        c.ring[hash] = node
        c.sortedKeys = append(c.sortedKeys, hash)
    }
    sort.Slice(c.sortedKeys, func(i, j int) bool {
        return c.sortedKeys[i] < c.sortedKeys[j]
    })
}

func (c *ConsistentHash) Get(key string) string {
    hash := c.hash(key)
    // 二分查找第一个 >= hash 的节点
    idx := sort.Search(len(c.sortedKeys), func(i int) bool {
        return c.sortedKeys[i] >= hash
    })
    if idx == len(c.sortedKeys) {
        idx = 0
    }
    return c.ring[c.sortedKeys[idx]]
}
```

### 虚拟节点

```
问题：节点少时，数据分布不均匀
解决：每个物理节点映射多个虚拟节点（如 150 个）
```

---

## 三、缓存穿透

### 问题

```
查询 id=-1 的数据（不存在）
每次都穿透到 DB，DB 压力大
```

### 解决方案

**方案1：空值缓存**

```go
func Get(key string) (string, error) {
    // 1. 查缓存
    val := redis.Get(key)
    if val == "NULL" {
        return "", nil  // 空值标记
    }
    if val != "" {
        return val, nil
    }
    
    // 2. 查 DB
    data := db.Get(key)
    if data == "" {
        // 缓存空值，短过期时间
        redis.Set(key, "NULL", 5*time.Minute)
        return "", nil
    }
    
    redis.Set(key, data, 1*time.Hour)
    return data, nil
}
```

**方案2：布隆过滤器**

```go
var bloomFilter *bloom.BloomFilter

func init() {
    // 初始化时加载所有存在的 key
    bloomFilter = bloom.New(1000000, 5)
    keys := db.GetAllKeys()
    for _, key := range keys {
        bloomFilter.Add([]byte(key))
    }
}

func Get(key string) (string, error) {
    // 1. 布隆过滤器判断
    if !bloomFilter.Test([]byte(key)) {
        return "", nil  // 一定不存在
    }
    
    // 2. 可能存在，查缓存和 DB
    // ...
}
```

---

## 四、缓存击穿

### 问题

```
热点 key 过期瞬间，大量请求同时打到 DB
```

### 解决方案

**方案1：互斥锁**

```go
func GetWithLock(key string) (string, error) {
    val := redis.Get(key)
    if val != "" {
        return val, nil
    }
    
    // 获取分布式锁
    lockKey := "lock:" + key
    if redis.SetNX(lockKey, "1", 10*time.Second) {
        defer redis.Del(lockKey)
        
        // 双重检查
        val = redis.Get(key)
        if val != "" {
            return val, nil
        }
        
        // 查 DB 并回填
        data := db.Get(key)
        redis.Set(key, data, 1*time.Hour)
        return data, nil
    }
    
    // 未获取到锁，等待后重试
    time.Sleep(100 * time.Millisecond)
    return GetWithLock(key)
}
```

**方案2：逻辑过期**

```go
type CacheValue struct {
    Data      string
    ExpireAt  int64  // 逻辑过期时间
}

func GetWithLogicalExpire(key string) string {
    val := redis.Get(key)
    if val == "" {
        return ""
    }
    
    var cv CacheValue
    json.Unmarshal([]byte(val), &cv)
    
    // 未过期，直接返回
    if cv.ExpireAt > time.Now().Unix() {
        return cv.Data
    }
    
    // 已过期，异步更新
    go func() {
        if redis.SetNX("lock:"+key, "1", 10*time.Second) {
            defer redis.Del("lock:" + key)
            data := db.Get(key)
            cv := CacheValue{Data: data, ExpireAt: time.Now().Unix() + 3600}
            redis.Set(key, json.Marshal(cv), 0)  // 永不过期
        }
    }()
    
    // 返回旧数据
    return cv.Data
}
```

---

## 五、缓存雪崩

### 问题

```
大量 key 同时过期，或 Redis 宕机
所有请求打到 DB，DB 被打垮
```

### 解决方案

```go
// 1. 过期时间加随机值
func SetWithRandomExpire(key, value string, baseExpire time.Duration) {
    // 基础过期时间 + 随机 0~5 分钟
    expire := baseExpire + time.Duration(rand.Intn(300))*time.Second
    redis.Set(key, value, expire)
}

// 2. 多级缓存
func GetWithMultiCache(key string) string {
    // L1: 本地缓存
    if val := localCache.Get(key); val != "" {
        return val
    }
    
    // L2: Redis
    if val := redis.Get(key); val != "" {
        localCache.Set(key, val, 1*time.Minute)
        return val
    }
    
    // L3: DB
    val := db.Get(key)
    redis.Set(key, val, 1*time.Hour)
    localCache.Set(key, val, 1*time.Minute)
    return val
}

// 3. 熔断降级
func GetWithCircuitBreaker(key string) string {
    if circuitBreaker.IsOpen() {
        return getDefaultValue(key)  // 降级返回默认值
    }
    // 正常查询...
}
```

---

## 六、缓存一致性

### 常见策略

| 策略 | 流程 | 问题 |
|------|------|------|
| 先更新DB，再删缓存 | 更新DB → 删缓存 | 删缓存失败导致不一致 |
| 先删缓存，再更新DB | 删缓存 → 更新DB | 并发读导致脏数据 |
| **延迟双删** | 删缓存 → 更新DB → 延迟再删 | 推荐 |
| Canal 监听 | 监听 binlog 更新缓存 | 最终一致 |

### 延迟双删

```go
func Update(key string, value string) error {
    // 1. 先删缓存
    redis.Del(key)
    
    // 2. 更新 DB
    db.Update(key, value)
    
    // 3. 延迟再删（防止并发读写导致脏数据）
    go func() {
        time.Sleep(500 * time.Millisecond)
        redis.Del(key)
    }()
    
    return nil
}
```

---

## 七、面试追问

| 问题 | 回答 |
|------|------|
| 缓存穿透怎么解决？ | 空值缓存 + 布隆过滤器 |
| 缓存击穿怎么解决？ | 互斥锁 或 逻辑过期 |
| 缓存雪崩怎么解决？ | 随机过期 + 多级缓存 + 熔断 |
| 如何保证一致性？ | 延迟双删 或 Canal 监听 |
| 一致性哈希虚拟节点作用？ | 解决数据分布不均匀问题 |
