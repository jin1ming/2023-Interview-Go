# 消息队列设计

## 一、核心功能

| 功能 | 说明 |
|------|------|
| 异步解耦 | 生产者消费者解耦 |
| 削峰填谷 | 缓冲突发流量 |
| 顺序消息 | 保证消息有序 |
| 事务消息 | 分布式事务 |
| 延迟消息 | 定时投递 |
| 死信队列 | 处理失败消息 |

---

## 二、整体架构

```
┌─────────────┐     ┌─────────────────────────────────┐     ┌─────────────┐
│   Producer  │────▶│           Broker                │────▶│  Consumer   │
└─────────────┘     │  ┌─────────────────────────┐    │     └─────────────┘
                    │  │  Topic: order           │    │
                    │  │  ├── Partition 0        │    │
                    │  │  ├── Partition 1        │    │
                    │  │  └── Partition 2        │    │
                    │  └─────────────────────────┘    │
                    │                                 │
                    │  ┌─────────────────────────┐    │
                    │  │  Topic: payment         │    │
                    │  │  ├── Partition 0        │    │
                    │  │  └── Partition 1        │    │
                    │  └─────────────────────────┘    │
                    └─────────────────────────────────┘
```

---

## 三、消息存储

### 顺序写 + 页缓存

```go
// Kafka 存储模型
type Partition struct {
    LogDir     string
    Segments   []*Segment  // 分段文件
    ActiveSeg  *Segment    // 当前写入的段
}

type Segment struct {
    BaseOffset int64       // 起始偏移量
    LogFile    *os.File    // 消息数据文件 (.log)
    IndexFile  *os.File    // 稀疏索引文件 (.index)
}

// 追加消息（顺序写）
func (p *Partition) Append(msg *Message) (int64, error) {
    offset := p.nextOffset()
    
    // 序列化消息
    data := serialize(msg)
    
    // 顺序写入（利用页缓存，性能极高）
    p.ActiveSeg.LogFile.Write(data)
    
    // 定期刷盘
    if p.shouldFlush() {
        p.ActiveSeg.LogFile.Sync()
    }
    
    return offset, nil
}
```

### 零拷贝

```go
// 传统方式：4次拷贝
// 磁盘 → 内核缓冲区 → 用户缓冲区 → Socket缓冲区 → 网卡

// 零拷贝：2次拷贝
// 磁盘 → 内核缓冲区 → 网卡（sendfile 系统调用）

func (p *Partition) SendTo(conn net.Conn, offset int64, size int64) error {
    file := p.getSegmentFile(offset)
    // sendfile 零拷贝
    return syscall.Sendfile(int(conn.Fd()), int(file.Fd()), &offset, int(size))
}
```

---

## 四、顺序消息

### 问题

```
订单消息：创建 → 支付 → 发货
如果乱序：发货 → 创建 → 支付（业务错误）
```

### 解决方案：分区有序

```go
// 同一订单的消息发到同一分区
func Send(topic string, orderID int64, msg *Message) error {
    // 按订单ID哈希选择分区
    partition := orderID % numPartitions
    
    return producer.Send(topic, partition, msg)
}

// 消费时：单分区单线程消费，保证有序
func Consume(topic string, partition int) {
    for msg := range consumer.Messages(topic, partition) {
        process(msg)  // 顺序处理
    }
}
```

### 全局有序（单分区）

```go
// 极端情况：全局有序，只用一个分区
// 缺点：吞吐量受限
topic := "global-order"
partition := 0  // 只有一个分区
```

---

## 五、事务消息

### 场景

```
下单时：
1. 创建订单（本地事务）
2. 发送消息通知库存扣减

问题：订单创建成功，消息发送失败？
```

### RocketMQ 事务消息

```go
// 1. 发送半消息（对消费者不可见）
func CreateOrder(order *Order) error {
    // 发送半消息
    transactionID := mq.SendHalfMessage("order-created", order)
    
    // 执行本地事务
    err := db.Create(order)
    
    if err != nil {
        // 本地事务失败，回滚消息
        mq.Rollback(transactionID)
        return err
    }
    
    // 本地事务成功，提交消息
    mq.Commit(transactionID)
    return nil
}

// 2. 事务回查（防止提交/回滚丢失）
func CheckTransaction(transactionID string) TransactionStatus {
    // 查询本地事务状态
    order := db.GetByTransactionID(transactionID)
    if order != nil {
        return COMMIT
    }
    return ROLLBACK
}
```

### 流程图

```
Producer                    Broker                    Consumer
    │                          │                          │
    │──── 1.发送半消息 ────────▶│                          │
    │◀─── 2.返回成功 ──────────│                          │
    │                          │                          │
    │  3.执行本地事务           │                          │
    │                          │                          │
    │──── 4.提交/回滚 ─────────▶│                          │
    │                          │──── 5.投递消息 ──────────▶│
    │                          │                          │
    │                          │                          │
    │◀─── 6.事务回查 ──────────│  (如果4丢失)              │
    │──── 7.返回状态 ──────────▶│                          │
```

---

## 六、延迟消息

### 实现方案

```go
// 方案1：多级延迟队列（RocketMQ）
// 预设延迟级别：1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h

func SendDelayMessage(topic string, msg *Message, delayLevel int) {
    msg.DelayLevel = delayLevel  // 如 level=3 表示 10s
    producer.Send(topic, msg)
}

// 方案2：时间轮（自实现）
type TimeWheel struct {
    slots     []*list.List  // 时间槽
    tickMs    int64         // 每槽时间间隔
    wheelSize int           // 槽数量
    currentSlot int
}

func (tw *TimeWheel) Add(task *DelayTask) {
    delaySlots := task.DelayMs / tw.tickMs
    targetSlot := (tw.currentSlot + int(delaySlots)) % tw.wheelSize
    tw.slots[targetSlot].PushBack(task)
}

func (tw *TimeWheel) Run() {
    ticker := time.NewTicker(time.Duration(tw.tickMs) * time.Millisecond)
    for range ticker.C {
        tw.currentSlot = (tw.currentSlot + 1) % tw.wheelSize
        tasks := tw.slots[tw.currentSlot]
        for e := tasks.Front(); e != nil; e = e.Next() {
            task := e.Value.(*DelayTask)
            go task.Execute()
        }
        tasks.Init()  // 清空当前槽
    }
}
```

---

## 七、死信队列

### 什么是死信

```
1. 消息被拒绝（reject/nack）
2. 消息过期（TTL）
3. 队列满了
4. 消费重试超过最大次数
```

### 处理流程

```go
func Consume(msg *Message) {
    retryCount := msg.GetRetryCount()
    
    err := process(msg)
    if err != nil {
        if retryCount < maxRetry {
            // 重试
            msg.SetRetryCount(retryCount + 1)
            mq.SendDelay("retry-topic", msg, getRetryDelay(retryCount))
        } else {
            // 进入死信队列
            mq.Send("dead-letter-topic", msg)
            // 告警
            alert("消息处理失败", msg)
        }
        return
    }
    
    // 确认消费
    msg.Ack()
}

// 重试间隔递增
func getRetryDelay(retryCount int) time.Duration {
    delays := []time.Duration{1*time.Second, 5*time.Second, 30*time.Second, 1*time.Minute, 5*time.Minute}
    if retryCount >= len(delays) {
        return delays[len(delays)-1]
    }
    return delays[retryCount]
}
```

---

## 八、消息可靠性

### 生产者可靠性

```go
// 同步发送 + 重试
func SendReliable(topic string, msg *Message) error {
    for i := 0; i < 3; i++ {
        err := producer.Send(topic, msg)
        if err == nil {
            return nil
        }
        time.Sleep(time.Duration(i+1) * time.Second)
    }
    return errors.New("发送失败")
}

// Kafka: acks=all 保证所有副本写入
producer.Config.RequiredAcks = sarama.WaitForAll
```

### 消费者可靠性

```go
// 手动提交 offset
func Consume(msg *Message) {
    err := process(msg)
    if err != nil {
        // 处理失败，不提交，会重新消费
        return
    }
    
    // 处理成功，提交 offset
    consumer.CommitOffset(msg)
}
```

---

## 九、面试追问

| 问题 | 回答 |
|------|------|
| 如何保证消息不丢？ | 生产者重试 + Broker 持久化 + 消费者手动ACK |
| 如何保证消息不重复？ | 消费端幂等（唯一ID去重） |
| 如何保证顺序？ | 同一业务ID发到同一分区，单线程消费 |
| Kafka 为什么快？ | 顺序写 + 页缓存 + 零拷贝 + 批量发送 |
| 事务消息原理？ | 半消息 + 本地事务 + 提交/回滚 + 回查 |
| 消息积压怎么办？ | 扩消费者 + 临时队列分流 + 降级 |
